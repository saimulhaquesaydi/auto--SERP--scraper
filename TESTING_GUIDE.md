# Testing Guide

## ğŸ§ª Testing Overview

This guide covers how to test the Google URL Scraper extension to ensure it works correctly.

## âœ… Pre-Testing Checklist

Before testing:
- [ ] Extension installed correctly
- [ ] Chrome version 88 or higher
- [ ] Stable internet connection
- [ ] Google.com accessible
- [ ] Developer tools available (F12)

## ğŸ¯ Test Scenarios

### 1. Basic Functionality Tests

#### Test 1.1: Extension Installation
```
Steps:
1. Load extension in Chrome
2. Check extension appears in toolbar
3. Click extension icon
4. Verify popup opens

Expected Result:
âœ… Popup shows "Ready" status
âœ… All buttons visible
âœ… No console errors
```

#### Test 1.2: Start Scraping
```
Steps:
1. Go to google.com
2. Search for "test"
3. Click extension icon
4. Click "Start Scraping"

Expected Result:
âœ… Badge shows "P1" (blue)
âœ… Status changes to "Scraping"
âœ… URLs start collecting
âœ… Page count increases
```

#### Test 1.3: Stop Scraping
```
Steps:
1. Start scraping (Test 1.2)
2. Wait for 2-3 pages
3. Click "Stop" button

Expected Result:
âœ… Badge shows "â¸" (orange)
âœ… Status changes to "Paused"
âœ… URLs preserved
âœ… Can resume later
```

#### Test 1.4: Download CSV
```
Steps:
1. Complete scraping session
2. Click "Download CSV"

Expected Result:
âœ… CSV file downloads
âœ… File contains URLs
âœ… One URL per line
âœ… Proper CSV format
```

#### Test 1.5: Copy to Clipboard
```
Steps:
1. Complete scraping session
2. Click "Copy URLs"
3. Paste in text editor

Expected Result:
âœ… URLs copied successfully
âœ… One URL per line
âœ… All URLs present
âœ… No duplicates
```

### 2. Resume Functionality Tests

#### Test 2.1: Resume After Manual Stop
```
Steps:
1. Start scraping
2. Stop after 3 pages
3. Click "Resume Scraping"

Expected Result:
âœ… Scraping continues from page 4
âœ… Previous URLs preserved
âœ… No duplicate URLs
âœ… Badge updates correctly
```

#### Test 2.2: Resume After Browser Restart
```
Steps:
1. Start scraping
2. Stop after 5 pages
3. Close browser completely
4. Reopen browser
5. Click extension icon
6. Click "Resume Scraping"

Expected Result:
âœ… Session data loaded
âœ… Shows previous progress
âœ… Can resume from page 6
âœ… All URLs preserved
```

#### Test 2.3: Resume After CAPTCHA
```
Steps:
1. Start scraping
2. Wait for CAPTCHA (or trigger it)
3. Solve CAPTCHA
4. Click "Resume Scraping"

Expected Result:
âœ… CAPTCHA detected automatically
âœ… Badge shows "âš ï¸" (red)
âœ… After solve, can resume
âœ… Continues from same page
```

### 3. CAPTCHA Handling Tests

#### Test 3.1: CAPTCHA Detection
```
Steps:
1. Start aggressive scraping
2. Wait for Google CAPTCHA

Expected Result:
âœ… Extension detects CAPTCHA
âœ… Automatically pauses
âœ… Badge shows "âš ï¸"
âœ… Notification appears
```

#### Test 3.2: CAPTCHA Recovery
```
Steps:
1. Trigger CAPTCHA (Test 3.1)
2. Solve CAPTCHA manually
3. Wait 5 seconds
4. Click "Resume"

Expected Result:
âœ… Scraping resumes
âœ… No errors occur
âœ… URLs continue collecting
âœ… Badge returns to blue
```

### 4. Data Management Tests

#### Test 4.1: Clear Data
```
Steps:
1. Complete scraping session
2. Click "Clear Data"
3. Confirm action

Expected Result:
âœ… All URLs cleared
âœ… Status resets to "Ready"
âœ… Badge clears
âœ… Can start fresh
```

#### Test 4.2: Data Persistence
```
Steps:
1. Scrape 50 URLs
2. Close popup (don't stop)
3. Reopen popup

Expected Result:
âœ… URLs still present
âœ… Count unchanged
âœ… Status preserved
âœ… Can continue or download
```

#### Test 4.3: Large Dataset
```
Steps:
1. Scrape 500+ URLs
2. Check performance
3. Download CSV

Expected Result:
âœ… No memory issues
âœ… UI remains responsive
âœ… CSV downloads successfully
âœ… All URLs present
```

### 5. Edge Case Tests

#### Test 5.1: No Search Results
```
Steps:
1. Search for "asdfghjklqwertyuiop"
2. Start scraping

Expected Result:
âœ… Handles gracefully
âœ… Shows "0 URLs"
âœ… Pauses automatically
âœ… No errors
```

#### Test 5.2: Single Page Results
```
Steps:
1. Search with few results
2. Start scraping

Expected Result:
âœ… Scrapes available URLs
âœ… Detects last page
âœ… Pauses automatically
âœ… Shows completion
```

#### Test 5.3: Tab Closed During Scraping
```
Steps:
1. Start scraping
2. Close Google search tab

Expected Result:
âœ… Extension detects closure
âœ… Automatically pauses
âœ… Data preserved
âœ… Notification shown
```

#### Test 5.4: Multiple Tabs
```
Steps:
1. Open 2 Google search tabs
2. Start scraping in tab 1
3. Try starting in tab 2

Expected Result:
âœ… Only one session active
âœ… Second start fails gracefully
âœ… Or first session stops
âœ… No data corruption
```

### 6. Performance Tests

#### Test 6.1: Speed Test
```
Steps:
1. Start scraping
2. Time 10 pages
3. Calculate pages/minute

Expected Result:
âœ… ~2-3 pages per minute
âœ… Consistent speed
âœ… No slowdown over time
âœ… Respects rate limits
```

#### Test 6.2: Memory Usage
```
Steps:
1. Open Chrome Task Manager
2. Start scraping
3. Monitor memory usage
4. Scrape 100+ pages

Expected Result:
âœ… Memory stays reasonable
âœ… No memory leaks
âœ… No browser slowdown
âœ… Extension remains responsive
```

#### Test 6.3: CPU Usage
```
Steps:
1. Monitor CPU usage
2. Start scraping
3. Check CPU during scraping

Expected Result:
âœ… Low CPU usage
âœ… No excessive processing
âœ… Browser remains responsive
âœ… Other tabs work normally
```

## ğŸ” Testing Tools

### Chrome DevTools
```
1. Press F12
2. Go to Console tab
3. Monitor for errors
4. Check Network tab for requests
```

### Extension Console
```
1. Go to chrome://extensions/
2. Find extension
3. Click "Inspect views: background page"
4. Monitor background script logs
```

### Storage Inspector
```javascript
// Check stored data
chrome.storage.local.get(['scraperData'], (result) => {
  console.log(result.scraperData);
});
```

## ğŸ“Š Test Results Template

```
Test Date: YYYY-MM-DD
Chrome Version: XX.X.XXXX.XX
Extension Version: 1.2.0

Test 1.1: âœ… PASS
Test 1.2: âœ… PASS
Test 1.3: âœ… PASS
Test 1.4: âŒ FAIL - CSV format issue
Test 1.5: âœ… PASS
...

Issues Found:
1. CSV header missing
2. Duplicate URLs in some cases
3. Badge not updating on slow connections

Notes:
- All critical tests passed
- Minor UI issues noted
- Performance acceptable
```

## ğŸ› Bug Reporting Template

```
Bug Title: [Brief description]

Steps to Reproduce:
1. Step one
2. Step two
3. Step three

Expected Behavior:
[What should happen]

Actual Behavior:
[What actually happens]

Environment:
- Chrome Version: XX.X
- Extension Version: 1.2.0
- OS: Windows/Mac/Linux

Console Errors:
[Paste any error messages]

Screenshots:
[Attach if relevant]
```

## âœ… Acceptance Criteria

### Must Pass
- âœ… Basic scraping works
- âœ… Resume functionality works
- âœ… CAPTCHA detection works
- âœ… Data persists correctly
- âœ… CSV export works
- âœ… No data loss
- âœ… No console errors

### Should Pass
- âœ… Badge updates correctly
- âœ… Notifications appear
- âœ… UI is responsive
- âœ… Performance is good
- âœ… Memory usage reasonable

### Nice to Have
- âœ… Handles all edge cases
- âœ… Graceful error recovery
- âœ… Helpful error messages
- âœ… Smooth animations

## ğŸš€ Automated Testing (Future)

### Unit Tests
```javascript
describe('URL Extraction', () => {
  test('extracts valid URLs', () => {
    // Test implementation
  });
  
  test('filters duplicates', () => {
    // Test implementation
  });
});
```

### Integration Tests
```javascript
describe('Scraping Flow', () => {
  test('complete scraping session', async () => {
    // Test implementation
  });
});
```

## ğŸ“ Testing Checklist

Before Release:
- [ ] All basic tests pass
- [ ] Resume functionality verified
- [ ] CAPTCHA handling tested
- [ ] Data persistence confirmed
- [ ] Performance acceptable
- [ ] No memory leaks
- [ ] No console errors
- [ ] Documentation updated
- [ ] Known issues documented
